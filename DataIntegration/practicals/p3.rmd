---
title: "Practical 3: Cluster Evaluation and Analysis"
subtitle: "EMBL Course: Data mining and integration with networks"
author: "Aaron Brooks"
date: "This should take about 20 minutes"
output:
  html_document:
    css: include/hint.css
    includes:
      in_header: include/hint.html
    toc: true
    toc_depth: 2
---

[Companion lecture](http://scalefreegan.github.io/Teaching/DataIntegration/lectures/l3.html)

# Choosing **k**

One of the most difficult aspects of clustering is choosing the "correct" number of clusters.

We have seen in the previous practicals how this can be accomplished informally by simple visual inspection of the data, for example. In other cases, the number of clusters may be motivated by the problem itself, i.e. some kind of prior expectation about the number of clusters. In most cases, however, you will want to have a more formal criteria with which to evaluate the *goodness* of clustering at a given **k**. Many methods and metrics have been proposed to accomplish this task. Here we will focus on three methods: the naive elbow method, spectral gap, and modularity maximization.

## Elbow method

## Spectral gap

## Modularity maximization

Because it would take too long to compute,

## Meta-communities

# Analyzing

## Node centrality






<div id='hint'>
<h5 class="ui-closed" style="color:blue">Hint</h5>
<div id='hint'>

</div>
